# Hugging Face LLM Course

This repository contains comprehensive Jupyter notebooks following the official [Hugging Face LLM Course](https://huggingface.co/learn/llm-course) for learning Large Language Models (LLMs) using Hugging Face's ecosystem of tools and libraries.

## ğŸ“š About

This course covers various aspects of working with LLMs, including:
- Transformer architecture fundamentals
- Using and fine-tuning pretrained models
- Working with datasets and tokenizers
- Building and sharing ML demos
- Advanced LLM fine-tuning techniques
- Creating reasoning models

## ğŸ“– Contents

- [ch-1.ipynb](ch-1.ipynb) - **Chapter 1: Transformer models**
- [ch-2.ipynb](ch-2.ipynb) - **Chapter 2: Using ğŸ¤— Transformers**
- [ch-3.ipynb](ch-3.ipynb) - **Chapter 3: Fine-tuning a pretrained model**
- [ch-4.ipynb](ch-4.ipynb) - **Chapter 4: Sharing models and tokenizers**
- [ch-5.ipynb](ch-5.ipynb) - **Chapter 5: The ğŸ¤— Datasets library**
- [ch-6.ipynb](ch-6.ipynb) - **Chapter 6: The ğŸ¤— Tokenizers library**
- [ch-7.ipynb](ch-7.ipynb) - **Chapter 7: Classical NLP tasks**
- [ch-8.ipynb](ch-8.ipynb) - **Chapter 8: How to ask for help**
- [ch-9.ipynb](ch-9.ipynb) - **Chapter 9: Building and sharing demos**
- [ch-10.ipynb](ch-10.ipynb) - **Chapter 10: Curate high-quality datasets**
- [ch-11.ipynb](ch-11.ipynb) - **Chapter 11: Fine-tune Large Language Models**
- [ch-12.ipynb](ch-12.ipynb) - **Chapter 12: Build Reasoning Models**

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- Jupyter Notebook or VS Code with Jupyter extension
- Basic understanding of Python and machine learning concepts

### Installation

1. Clone the repository:
```bash
git clone https://github.com/BUFONJOKER/huggingface-llm-course.git
cd huggingface-llm-course
```

2. Install the required dependencies:
```bash
pip install transformers datasets torch accelerate evaluate gradio argilla
```

3. Launch Jupyter Notebook or open in VS Code:
```bash
jupyter notebook
# or
code .
```

4. Follow along with the [official course](https://huggingface.co/learn/llm-course) chapter by chapter

All notebooks can also be run in Google Colab, and I will run them in VS Code using the Colab extension.

## ğŸ› ï¸ Technologies Used

- **ğŸ¤— Transformers**: State-of-the-art NLP and LLM models
- **ğŸ¤— Datasets**: Easy access to ML datasets
- **ğŸ¤— Tokenizers**: Fast and efficient tokenization
- **ğŸ¤— Accelerate**: Easy multi-GPU/TPU training
- **PyTorch**: Deep learning framework
- **Gradio**: Build and share ML demos
- **Argilla**: Dataset curation and annotation

## ğŸ”— Resources

- [Official Course](https://huggingface.co/learn/llm-course)
- [Hugging Face Hub](https://huggingface.co/)
- [Course Forums](https://discuss.huggingface.co/)
- [Documentation](https://huggingface.co/docs)

## ğŸ“ License

This project is open source and available for educational purposes.

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

## ğŸ“§ Contact

For questions or feedback, please open an issue in this repository.
