{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907f88bc",
   "metadata": {},
   "source": [
    "# Chapter 1: Transformer models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7fd62",
   "metadata": {},
   "source": [
    "## HuggingFace Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6175601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c7b7d",
   "metadata": {},
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98d8b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183bec4d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28534e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce7051466ca4f2789cc42c1126a46a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe15ce765cee40f0b35ee7320cfe3478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7912de1149b44e7082b1c17ce2028131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d66628a09ad4e1eb3c409efb467e9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e26dc356fd40e1bf58585da2f09fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "787b4b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998134970664978}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I love Pakistan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bc178c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.804728090763092}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I love Pakistan but hate sindh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f93f4fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9995508790016174},\n",
       " {'label': 'NEGATIVE', 'score': 0.9984190464019775}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"apple have good mobiles\", \"apple mobiles are expensive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8e79ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9955568909645081}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"samsung mobiles are good but they became very good after 5 years of usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c277b",
   "metadata": {},
   "source": [
    "## Text Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86093ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf085bb08c84ff18453367ffd582495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f99af6d96344c19d761458f8dea71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdcd70394f74f0db463036b22ddb30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: openai-community/gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d41a85f70a49e1bb5c05063cc05ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aba33c20db84d09a127db19ef444f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb670c24d4204213b749b33fdff2d760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c6d1610c9e474c891dbb2080980b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7738dc8d03e44e4ea67c86a73c5f1206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to create and use a custom object in the JavaScript language. The goal of this course is to provide you with the tools and resources to create and use a custom object in JavaScript.\\n\\nThis course is open to students who have not completed a course on JavaScript in the previous year.\\n\\nYou will be able to create custom objects in JavaScript using the following methods:\\n\\nvar obj = Object.create(obj);\\n\\nYou will be able to add a custom function that will call the function object from your script in the JavaScript class.\\n\\nvar b = {}; var c = function(e,t){this.e.b.apply(t); };\\n\\nThis class will be used to create a custom object from JavaScript and create a new custom object from the existing object that will be in the class.\\n\\nYou will also need to know how to create custom objects in JavaScript using the constructor methods.\\n\\nIf you have not completed a course on JavaScript in the previous year, you will get a special notice:\\n\\nYou will be able to create a custom object in JavaScript using the constructor methods.\\n\\nIf you have not completed a course on JavaScript in the previous year, you will get a special notice:\\n\\nYou will be'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd8fe0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e4fc07eaca4e4ba4041796b5a70ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63ae73f49664cd6bb8e379f75e4741f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9045970bc0544c67929d5112b0b0f595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b43b5bea434e878334d2045ee3b105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09e5101b2de4631ab527bbe6d9f5ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dd16fe9b144a449bf8ad7fed53b8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165b6f5363fa411e872e2c1e2e46ad3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_shot_classifier = pipeline('zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d150fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'There are 40 schools in punjab',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9612680673599243, 0.02439768612384796, 0.014334327541291714]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classifier(\n",
    "    \"There are 40 schools in punjab\",\n",
    "    candidate_labels=['politics','business','education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c642847e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'There are 40 schools in punjab',\n",
       " 'labels': ['violence', 'politics', 'crime'],\n",
       " 'scores': [0.4787311851978302, 0.31286999583244324, 0.20839884877204895]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classifier(\n",
    "    \"There are 40 schools in punjab\",\n",
    "    candidate_labels=['politics','violence','crime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d51189c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'There are 40 schools in punjab',\n",
       " 'labels': ['violence', 'crime'],\n",
       " 'scores': [0.6967111825942993, 0.3032888174057007]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classifier(\n",
    "    \"There are 40 schools in punjab\",\n",
    "    candidate_labels=['violence','crime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52b3170a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3db551832dc4c24a4aed54657d2c75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0975086d531d466e834e91ccfc546377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/724M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fef355824b445b87d89fcee855b92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecfb822916742d58a67d7f6d57d9c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4043770d8e442d1866a20746b137e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470264dc8be34fb784b398710859e7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749bc8b3ebb24fbf883dc64ed3b325b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnerator = pipeline('text-generation', model=\"HuggingFaceTB/SmolLM2-360M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbcb746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'num_return_sequences', 'max_new_tokens'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=20) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'NLP stands for natural language processing, it is a part of machine learning or AI in general. It also works in an \"interaction model\" and can learn from other models by'},\n",
       " {'generated_text': 'NLP stands for natural language processing, it is a part of machine learning or AI. In fact, many AI experts have warned that AI could be a great way to improve our understanding'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"NLP stands for natural language processing, it is a part of machine learning or AI\", num_return_sequences=2, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cb3c945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27264cf6e9e43b89802dc7aa7f66ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8438e0864a234f4681a851472f5f2bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abf379384cb4d9691f2023d3d586aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322d10c769224955a1c65064a60116ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbd0d8e61e44ffa89f3981fcfa9630d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5c7bffc3b44c77a5827e767400aea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b197ffba7a0e46c787bdadec0933781a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43802f54b61b43f38b1089c6e85e55f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bd0cdc465c43b19dcc0c1f679b9ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8d32f4cfba4430b7b004d77aa846f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnerator = pipeline('text-generation', model=\"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2723c387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=70) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Transformers are neural network architecture used in most llm models today. For example, a neural network may be built on top of a neuron, and is able to use data from the neurons without the need of a neural network.\\n\\nWhat is the effect of the neural network architecture?\\n\\nWe have analyzed the effect of the neural network architecture on the speed of the training. This is because the training algorithm'},\n",
       " {'generated_text': 'Transformers are neural network architecture used in most llm models today that uses convolutional neural networks to perform tasks such as model recognition and machine learning (Mali et al., 2001).\\n\\nIn this paper, we explore a new approach to solving neural network problems that uses the same approach to model data and models in order to understand a broad range of applications. We also explore the feasibility of using deep learning'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Transformers are neural network architecture used in most llm models today\", num_return_sequences=2, max_new_tokens=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0200f",
   "metadata": {},
   "source": [
    "## Fill Masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37ca48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb114bdb67b4ba9960cae397f0c32a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98ecc1081f84315a98eef72023e2cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932d224762bb476bb1293dc504f1906f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaForMaskedLM LOAD REPORT from: distilbert/distilroberta-base\n",
      "Key                         | Status     |  | \n",
      "----------------------------+------------+--+-\n",
      "roberta.pooler.dense.bias   | UNEXPECTED |  | \n",
      "roberta.pooler.dense.weight | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ae0a9af72d4096a8d5e9bf4078d212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5397b4ef226425b8ae3f9ad882b4db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e427aa9d1464d4ca78b713a7337679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476b3ff2a33b4e74b4e10a9ef070a4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a62ae846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.31632283329963684,\n",
       "  'token': 16441,\n",
       "  'token_str': ' republic',\n",
       "  'sequence': 'Pakistan is a republic in south asia'},\n",
       " {'score': 0.11328057944774628,\n",
       "  'token': 4593,\n",
       "  'token_str': ' democracy',\n",
       "  'sequence': 'Pakistan is a democracy in south asia'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Pakistan is a <mask> in south asia\",top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef02e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"hf-inference\",\n",
    ")\n",
    "\n",
    "result = client.token_classification(\n",
    "    \"My name is Sarah Jessica Parker but you can call me Jessica\",\n",
    "    model=\"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58b4d5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenClassificationOutputElement(end=2, score=0.83775586, start=0, word='My', entity=None, entity_group='LABEL_0'),\n",
       " TokenClassificationOutputElement(end=7, score=0.6066385, start=3, word='name', entity=None, entity_group='LABEL_1'),\n",
       " TokenClassificationOutputElement(end=10, score=0.8748416, start=8, word='is', entity=None, entity_group='LABEL_0'),\n",
       " TokenClassificationOutputElement(end=31, score=0.9610941, start=11, word='Sarah Jessica Parker', entity=None, entity_group='LABEL_1'),\n",
       " TokenClassificationOutputElement(end=43, score=0.94660324, start=32, word='but you can', entity=None, entity_group='LABEL_0'),\n",
       " TokenClassificationOutputElement(end=51, score=0.8567872, start=44, word='call me', entity=None, entity_group='LABEL_1'),\n",
       " TokenClassificationOutputElement(end=59, score=0.99906343, start=52, word='Jessica', entity=None, entity_group='LABEL_0')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04f37c",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e3956e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3440bf00dac41c1a616982383317041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4389a306145145d9bdb69293e31b0999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4cd07d4efa41aaa17901e5cdad4acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification LOAD REPORT from: dbmdz/bert-large-cased-finetuned-conll03-english\n",
      "Key                      | Status     |  | \n",
      "-------------------------+------------+--+-\n",
      "bert.pooler.dense.bias   | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a747941ace24935b495dbac817067bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2bd6261d124d269ffe820bf3bef853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "named_entity_recognition = pipeline(\"ner\", aggregation_strategy='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cd3c4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9981694),\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9796019),\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9932106),\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entity_recognition(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bdce8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9445622),\n",
       "  'word': 'Mani',\n",
       "  'start': 0,\n",
       "  'end': 4},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.99980396),\n",
       "  'word': 'Pakistan',\n",
       "  'start': 14,\n",
       "  'end': 22}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entity_recognition(\"Mani lives in Pakistan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4daca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = named_entity_recognition(\"Mani did BSCS from IUB, he is the leader of criminal organization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc9238e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730f7bf",
   "metadata": {},
   "source": [
    "## Part-of-Speech (POS) Tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9594caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c318159d78484bdfa12bc4b7e987b71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3907afe0d7a4ecf9cca2fa0bf94ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255a4a32ff6f4dad8628b50e15bc95f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification LOAD REPORT from: sagorsarker/codeswitch-spaeng-pos-lince\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias       | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight     | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cc4f473c1a4530ba44437962a0070a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7616faccb7e94433bbb820ea3fb9ccd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c16d14fdd814da996523f116d047dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"token-classification\", model=\"sagorsarker/codeswitch-spaeng-pos-lince\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7948828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'PROPN',\n",
       "  'score': np.float32(0.9996001),\n",
       "  'index': 1,\n",
       "  'word': 'Mani',\n",
       "  'start': 0,\n",
       "  'end': 4},\n",
       " {'entity': 'VERB',\n",
       "  'score': np.float32(0.999686),\n",
       "  'index': 2,\n",
       "  'word': 'did',\n",
       "  'start': 5,\n",
       "  'end': 8},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9984781),\n",
       "  'index': 3,\n",
       "  'word': 'BS',\n",
       "  'start': 9,\n",
       "  'end': 11},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9490655),\n",
       "  'index': 4,\n",
       "  'word': '##CS',\n",
       "  'start': 11,\n",
       "  'end': 13},\n",
       " {'entity': 'ADP',\n",
       "  'score': np.float32(0.99969816),\n",
       "  'index': 5,\n",
       "  'word': 'from',\n",
       "  'start': 14,\n",
       "  'end': 18},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.99854076),\n",
       "  'index': 6,\n",
       "  'word': 'I',\n",
       "  'start': 19,\n",
       "  'end': 20},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9983956),\n",
       "  'index': 7,\n",
       "  'word': '##UB',\n",
       "  'start': 20,\n",
       "  'end': 22},\n",
       " {'entity': 'PUNCT',\n",
       "  'score': np.float32(0.922772),\n",
       "  'index': 8,\n",
       "  'word': ',',\n",
       "  'start': 22,\n",
       "  'end': 23},\n",
       " {'entity': 'PRON',\n",
       "  'score': np.float32(0.99989355),\n",
       "  'index': 9,\n",
       "  'word': 'he',\n",
       "  'start': 24,\n",
       "  'end': 26},\n",
       " {'entity': 'VERB',\n",
       "  'score': np.float32(0.99974257),\n",
       "  'index': 10,\n",
       "  'word': 'is',\n",
       "  'start': 27,\n",
       "  'end': 29},\n",
       " {'entity': 'DET',\n",
       "  'score': np.float32(0.99973136),\n",
       "  'index': 11,\n",
       "  'word': 'the',\n",
       "  'start': 30,\n",
       "  'end': 33},\n",
       " {'entity': 'NOUN',\n",
       "  'score': np.float32(0.9964018),\n",
       "  'index': 12,\n",
       "  'word': 'leader',\n",
       "  'start': 34,\n",
       "  'end': 40},\n",
       " {'entity': 'ADP',\n",
       "  'score': np.float32(0.99951124),\n",
       "  'index': 13,\n",
       "  'word': 'of',\n",
       "  'start': 41,\n",
       "  'end': 43},\n",
       " {'entity': 'ADJ',\n",
       "  'score': np.float32(0.9988526),\n",
       "  'index': 14,\n",
       "  'word': 'criminal',\n",
       "  'start': 44,\n",
       "  'end': 52},\n",
       " {'entity': 'NOUN',\n",
       "  'score': np.float32(0.9998192),\n",
       "  'index': 15,\n",
       "  'word': 'organization',\n",
       "  'start': 53,\n",
       "  'end': 65}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mani did BSCS from IUB, he is the leader of criminal organization\"\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbf846",
   "metadata": {},
   "source": [
    "## Question Answering (QA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "925284cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc417da76224df390af2ed74a503c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168dcdb718bb4253871b62fee909547f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d39f3e8f4484db3064e356bfc4e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8772d9d21eb844bebee95623a8c18166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8af7b303cd4cb69dc84f756faa6914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071f19232b1a43448bd23c50e6065f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b38d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9831763290567324, 'start': 64, 'end': 73, 'answer': 'Islamabad'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=\"What is the capital of Pakistan?\",\n",
    "    context=\"Pakistan is a country in South Asia. The capital of Pakistan is Islamabad.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0cd3c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd06eb15fd944de7870aac5e45203a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BartForCausalLM LOAD REPORT from: facebook/bart-large-cnn\n",
      "Key                                                       | Status     |  | \n",
      "----------------------------------------------------------+------------+--+-\n",
      "model.encoder.layers.{0...11}.final_layer_norm.bias       | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.v_proj.bias       | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.final_layer_norm.weight     | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.q_proj.weight     | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.fc1.bias                    | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.fc1.weight                  | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.q_proj.bias       | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.out_proj.weight   | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.fc2.weight                  | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.v_proj.weight     | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.k_proj.weight     | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn_layer_norm.bias   | UNEXPECTED |  | \n",
      "model.encoder.layernorm_embedding.weight                  | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.out_proj.bias     | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.fc2.bias                    | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn.k_proj.bias       | UNEXPECTED |  | \n",
      "model.encoder.layers.{0...11}.self_attn_layer_norm.weight | UNEXPECTED |  | \n",
      "model.encoder.embed_positions.weight                      | UNEXPECTED |  | \n",
      "model.encoder.layernorm_embedding.bias                    | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '\\nThe Hugging Face Transformers library provides thousands of pretrained models \\nto perform tasks on different modalities such as text, vision, and audio. \\nThese models can be used to demonstrate how to solve complex problems with \\njust a few lines of code using the pipeline API.\\n'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Specifying the model manually often bypasses registry lookups\n",
    "summarizer = pipeline(\"text-generation\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "text = \"\"\"\n",
    "The Hugging Face Transformers library provides thousands of pretrained models \n",
    "to perform tasks on different modalities such as text, vision, and audio. \n",
    "These models can be used to demonstrate how to solve complex problems with \n",
    "just a few lines of code using the pipeline API.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarizer(text, max_length=30, min_length=10, do_sample=False)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses) (2025.11.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses) (1.5.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sacremoses) (4.67.1)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n"
     ]
    }
   ],
   "source": [
    "# pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1169c",
   "metadata": {},
   "source": [
    "## Translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90c2b566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7211ab65c98b4ad99e473566faa2d060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This course is produced by Hugging Face.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "text = \"Ce cours est produit par Hugging Face.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70fdbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"Ce cours est produit par Hugging Face.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e05384f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59513,   160,  1031,    32,  3102,    46,   452, 13966,   101, 14543,\n",
       "             3,     0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aae77f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This course is produced by Hugging Face.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69c03447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonjour, comment allez-vous?\n",
      "English: Hello, how are you?\n",
      "\n",
      "French: J'aime apprendre de nouvelles langues.\n",
      "English: I like to learn new languages.\n",
      "\n",
      "French: Paris est la capitale de la France.\n",
      "English: Paris is the capital of France.\n",
      "\n",
      "French: Il fait beau aujourd'hui.\n",
      "English: It's beautiful today.\n",
      "\n",
      "French: Je voudrais un caf, s'il vous plat.\n",
      "English: I'd like some coffee, please.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "french_sentences = [\n",
    "    \"Bonjour, comment allez-vous?\",\n",
    "    \"J'aime apprendre de nouvelles langues.\",\n",
    "    \"Paris est la capitale de la France.\",\n",
    "    \"Il fait beau aujourd'hui.\",\n",
    "    \"Je voudrais un caf, s'il vous plat.\"\n",
    "]\n",
    "\n",
    "for sentence in french_sentences:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"French: {sentence}\")\n",
    "    print(f\"English: {translation}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a1280",
   "metadata": {},
   "source": [
    "## Image Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "379bc0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029940626b12466098dd9a301964a954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51e872df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = image_classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a592e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'lynx, catamount', 'score': 0.43350017070770264}, {'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 'score': 0.03479619696736336}, {'label': 'snow leopard, ounce, Panthera uncia', 'score': 0.03240185230970383}, {'label': 'Egyptian cat', 'score': 0.023944752290844917}, {'label': 'tiger cat', 'score': 0.022889167070388794}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4b96e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = image_classifier(\"book.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3abe05fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f53c83c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'book jacket, dust cover, dust jacket, dust wrapper',\n",
       " 'score': 0.635678231716156}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "610629e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'book jacket, dust cover, dust jacket, dust wrapper', 'score': 0.635678231716156}\n",
      "{'label': 'binder, ring-binder', 'score': 0.30658555030822754}\n",
      "{'label': 'bookcase', 'score': 0.009401485323905945}\n",
      "{'label': 'library', 'score': 0.004495835397392511}\n",
      "{'label': 'bookshop, bookstore, bookstall', 'score': 0.004475861322134733}\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2627fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'mortarboard', 'score': 0.8423728346824646}\n",
      "{'label': \"academic gown, academic robe, judge's robe\", 'score': 0.1544877588748932}\n",
      "{'label': 'bearskin, busby, shako', 'score': 0.00014484967687167227}\n",
      "{'label': 'vestment', 'score': 0.00012590135156642646}\n",
      "{'label': 'bookcase', 'score': 0.00010982630919897929}\n"
     ]
    }
   ],
   "source": [
    "result = image_classifier(\"images.jpg\")\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00adc6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'mask', 'score': 0.41627171635627747}\n",
      "{'label': 'wig', 'score': 0.08238478749990463}\n",
      "{'label': 'bow tie, bow-tie, bowtie', 'score': 0.05209118872880936}\n",
      "{'label': \"plunger, plumber's helper\", 'score': 0.023010728880763054}\n",
      "{'label': 'Windsor tie', 'score': 0.018288493156433105}\n"
     ]
    }
   ],
   "source": [
    "result = image_classifier(\"download.jpg\")\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a32b69",
   "metadata": {},
   "source": [
    "## Automatic Speech Recognition (ASR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "347a341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4a6f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d16e0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50bab26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (3.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Downloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 5.0.0\n",
      "    Uninstalling transformers-5.0.0:\n",
      "      Successfully uninstalled transformers-5.0.0\n",
      "Successfully installed transformers-5.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "bb656ddf0d6346e5bea30c8030b5dd69",
       "pip_warning": {
        "packages": [
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install --upgrade transformers librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "38dc1bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0914bdb13e604724b764ab5497deac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Option 1: Pass the file path directly to the pipeline\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\", \n",
    "    model=\"openai/whisper-large-v3\", \n",
    "    torch_dtype=torch.float16, \n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b9d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets[audio] in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (1.3.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (6.0.3)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (0.13.1)\n",
      "Collecting torchcodec>=0.4.0 (from datasets[audio])\n",
      "  Downloading torchcodec-0.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from datasets[audio]) (2.9.0+cu126)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets[audio]) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets[audio]) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets[audio]) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets[audio]) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets[audio]) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets[audio]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets[audio]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets[audio]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets[audio]) (2026.1.4)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->datasets[audio]) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.0->datasets[audio]) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets[audio]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets[audio]) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets[audio]) (1.22.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (3.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets[audio]) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets[audio]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets[audio]) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.7.0->datasets[audio]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.7.0->datasets[audio]) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets[audio]) (8.3.1)\n",
      "Downloading torchcodec-0.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9e1fd128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f43c8482e044b2860779d94ad16018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have a dream that one day this nation will rise up and live out the true meaning of its creed.\n"
     ]
    }
   ],
   "source": [
    "# Workaround: Use model and processor directly\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "# Load the processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    \"openai/whisper-large-v3\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "# Load audio file with librosa and resample to 16000Hz\n",
    "audio_array, sampling_rate = librosa.load(\"mlk.flac\", sr=16000)\n",
    "\n",
    "# Process and transcribe\n",
    "inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "# Convert inputs to float16 to match model dtype\n",
    "inputs = {k: v.to(\"cuda\").to(torch.float16) if v.dtype == torch.float32 else v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "# Generate transcription\n",
    "generated_ids = model.generate(**inputs)\n",
    "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
